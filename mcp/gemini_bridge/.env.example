# Gemini API Configuration
# Get your API key from: https://aistudio.google.com/
GEMINI_API_KEY=your_gemini_api_key_here

# Optional Configuration
# Maximum file size in bytes (default: 25MB or 25 × 1024² = 26 214 400 bytes)
MAX_FILE_SIZE=26214400

# Maximum total tokens to send (default: 900,000)
# Leave some room for output tokens, assuming a 1,048,576 token limit
MAX_TOTAL_TOKENS=900000

# Default model to use
# https://ai.google.dev/gemini-api/docs/models
# Options: gemini-2.5-pro-preview-06-05, gemini-2.5-flash-preview-05-20, gemini-2.0-flash
DEFAULT_MODEL=gemini-2.5-flash-preview-05-20

# Allowed models - comma-separated list (optional)
# Leave empty to allow any gemini-* model
# Use prefixes like "gemini-2.5-preview" to allow all preview versions
ALLOWED_MODELS=

# Pattern analysis default model (for code analysis tasks)
PATTERN_ANALYSIS_MODEL=gemini-2.5-pro-preview-06-05

# Token Estimation Configuration
# Characters per token approximation (default: 4)
# Gemini uses a similar tokenization to GPT models
CHARS_PER_TOKEN=4

# Token estimation buffer multiplier (default: 1.2 = 20% buffer)
# Increase if you're hitting token limits unexpectedly
TOKEN_ESTIMATION_BUFFER=1.2

# File Handling Configuration
# Maximum file size in bytes (default: 25MB = 25 x 1024² = 26214400 bytes)
MAX_FILE_SIZE=26214400

# Maximum total tokens to send (default: 900,000)
# Leave room for output tokens
MAX_TOTAL_TOKENS=900000

# File Discovery Configuration
# Excluded file extensions - comma-separated (optional)
# These are always treated as binary regardless of content
EXCLUDED_EXTENSIONS=.exe,.dll,.so,.dylib,.zip,.tar,.gz,.rar,.7z,.jpg,.jpeg,.png,.gif,.bmp,.ico,.webp,.mp3,.mp4,.avi,.mov,.wmv,.flv,.webm,.woff,.woff2,.ttf,.eot,.otf,.db,.sqlite,.lock

# Force text extensions - comma-separated (optional)
# These are treated as text even if they might appear binary (like PDFs)
FORCE_TEXT_EXTENSIONS=.pdf,.svg

# Excluded directories - comma-separated (optional)
# Default excludes common build/dependency directories
EXCLUDED_DIRS=node_modules,.git,dist,build,coverage,.next,.nuxt,vendor,__pycache__,.pytest_cache,venv,.venv

# Binary file detection - bytes to check (default: 8192)
# Files are checked for binary content by examining the first N bytes
BINARY_CHECK_BYTES=8192

# Performance Configuration
# Maximum directory recursion depth (default: 12)
MAX_RECURSION_DEPTH=12

# Default maximum files to return in discovery (default: 50)
DEFAULT_MAX_FILES=50

# Gemini Generation Configuration (optional)
# Temperature for response generation (0.0-1.0, default: 0.1)
GEMINI_TEMPERATURE=0.1

# Top-K sampling (default: 40)
GEMINI_TOP_K=40

# Top-P (nucleus) sampling (default: 0.95)
GEMINI_TOP_P=0.95

# Maximum output tokens (default: 65536)
GEMINI_MAX_OUTPUT_TOKENS=65536

# Iterative Refinement Configuration
# Enable automatic iterative refinement for better quality responses
ENABLE_ITERATIVE_REFINEMENT=false

# Maximum number of refinement iterations (default: 3)
MAX_ITERATIONS=3

# Prompt prefix for refinement iterations
ITERATION_PROMPT_PREFIX=The previous response may need refinement. Please review and improve your answer, focusing on:

# Triggers that indicate a response needs refinement (pipe-separated)
# These words in the response will trigger automatic refinement
ITERATION_TRIGGERS=unclear|incomplete|error|mistake|clarify|expand

# Smart Features Configuration
# Auto-fetch available models from Gemini API (default: true)
AUTO_FETCH_MODELS=true

# Model cache TTL in milliseconds (default: 1 hour)
MODEL_CACHE_TTL=3600000

# Enable smart error recovery with contextual suggestions (default: true)
ENABLE_SMART_RECOVERY=true

# Enable automatic context optimization when too large (default: true)
# This will sort by importance (smaller files first, then by extension priority)
ENABLE_AUTO_OPTIMIZATION=true